{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and loading data\n",
    "\n",
    "df = pd.read_csv('/Users/corneliastackhouse/Documents/Greenbootcamps/Test_Final_project/salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        work_year experience_level employment_type                  job_title  \\\n",
       "0           2025               SE              FT  Machine Learning Engineer   \n",
       "1           2025               SE              FT  Machine Learning Engineer   \n",
       "2           2025               SE              FT               Data Manager   \n",
       "3           2025               SE              FT               Data Manager   \n",
       "4           2025               MI              FT          Platform Engineer   \n",
       "...          ...              ...             ...                        ...   \n",
       "73407       2020               SE              FT             Data Scientist   \n",
       "73408       2021               MI              FT   Principal Data Scientist   \n",
       "73409       2020               EN              FT             Data Scientist   \n",
       "73410       2020               EN              CT      Business Data Analyst   \n",
       "73411       2021               SE              FT             Data Scientist   \n",
       "\n",
       "        salary salary_currency  salary_in_usd employee_residence  \\\n",
       "0       160000             USD         160000                 US   \n",
       "1       136000             USD         136000                 US   \n",
       "2        97600             USD          97600                 US   \n",
       "3        55800             USD          55800                 US   \n",
       "4       214500             USD         214500                 US   \n",
       "...        ...             ...            ...                ...   \n",
       "73407   412000             USD         412000                 US   \n",
       "73408   151000             USD         151000                 US   \n",
       "73409   105000             USD         105000                 US   \n",
       "73410   100000             USD         100000                 US   \n",
       "73411  7000000             INR          94665                 IN   \n",
       "\n",
       "       remote_ratio company_location company_size  \n",
       "0               100               US            M  \n",
       "1               100               US            M  \n",
       "2                 0               US            M  \n",
       "3                 0               US            M  \n",
       "4                 0               US            M  \n",
       "...             ...              ...          ...  \n",
       "73407           100               US            L  \n",
       "73408           100               US            L  \n",
       "73409           100               US            S  \n",
       "73410           100               US            L  \n",
       "73411            50               IN            L  \n",
       "\n",
       "[73412 rows x 11 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data exploration\n",
    "\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73412 entries, 0 to 73411\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   work_year           73412 non-null  int64 \n",
      " 1   experience_level    73412 non-null  object\n",
      " 2   employment_type     73412 non-null  object\n",
      " 3   job_title           73412 non-null  object\n",
      " 4   salary              73412 non-null  int64 \n",
      " 5   salary_currency     73412 non-null  object\n",
      " 6   salary_in_usd       73412 non-null  int64 \n",
      " 7   employee_residence  73412 non-null  object\n",
      " 8   remote_ratio        73412 non-null  int64 \n",
      " 9   company_location    73412 non-null  object\n",
      " 10  company_size        73412 non-null  object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work_year              int64\n",
       "experience_level      object\n",
       "employment_type       object\n",
       "job_title             object\n",
       "salary                 int64\n",
       "salary_currency       object\n",
       "salary_in_usd          int64\n",
       "employee_residence    object\n",
       "remote_ratio           int64\n",
       "company_location      object\n",
       "company_size          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work_year             0\n",
       "experience_level      0\n",
       "employment_type       0\n",
       "job_title             0\n",
       "salary                0\n",
       "salary_currency       0\n",
       "salary_in_usd         0\n",
       "employee_residence    0\n",
       "remote_ratio          0\n",
       "company_location      0\n",
       "company_size          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "\n",
    "# No Null Values found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(39146)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine Learning Engineer',\n",
       " 'Data Manager',\n",
       " 'Platform Engineer',\n",
       " 'Data Analyst',\n",
       " 'Data Scientist',\n",
       " 'Research Scientist',\n",
       " 'Developer',\n",
       " 'Manager',\n",
       " 'Software Engineer',\n",
       " 'Solutions Engineer',\n",
       " 'Solutions Architect',\n",
       " 'Architect',\n",
       " 'Product Manager',\n",
       " 'AI Engineer',\n",
       " 'Data Product Owner',\n",
       " 'Systems Engineer',\n",
       " 'Business Intelligence Developer',\n",
       " 'Engineer',\n",
       " 'Data Engineer',\n",
       " 'AI Architect',\n",
       " 'Analyst',\n",
       " 'Consultant',\n",
       " 'Data Governance',\n",
       " 'Applied Scientist',\n",
       " 'Data Analytics Manager',\n",
       " 'Associate',\n",
       " 'Data Management Specialist',\n",
       " 'Software Development Engineer',\n",
       " 'Machine Learning Scientist',\n",
       " 'Data Architect',\n",
       " 'Power BI Developer',\n",
       " 'Research Engineer',\n",
       " 'Quantitative Developer',\n",
       " 'Technical Lead',\n",
       " 'Sales Development Representative',\n",
       " 'System Engineer',\n",
       " 'Analytics Engineer',\n",
       " 'Solution Architect',\n",
       " 'Encounter Data Management Professional',\n",
       " 'Data Infrastructure Engineer',\n",
       " 'Data Team Lead',\n",
       " 'Business Intelligence Lead',\n",
       " 'DevOps Engineer',\n",
       " 'Decision Scientist',\n",
       " 'Data Visualization Engineer',\n",
       " 'Data Governance Analyst',\n",
       " 'Data Quality Analyst',\n",
       " 'Lead Analyst',\n",
       " 'Data Specialist',\n",
       " 'Software Developer',\n",
       " 'Business Intelligence Analyst',\n",
       " 'Engineering Manager',\n",
       " 'MLOps Engineer',\n",
       " 'Business Intelligence Engineer',\n",
       " 'Data Developer',\n",
       " 'Data and Reporting Analyst',\n",
       " 'Postdoctoral Fellow',\n",
       " 'Product Owner',\n",
       " 'Research Analyst',\n",
       " 'Data Reporting Analyst',\n",
       " 'Full Stack Engineer',\n",
       " 'Data Product Manager',\n",
       " 'Data Quality Engineer',\n",
       " 'Insight Analyst',\n",
       " 'Data Management Analyst',\n",
       " 'Product Designer',\n",
       " 'Principal Software Architect',\n",
       " 'Statistical Programmer',\n",
       " 'Business Intelligence',\n",
       " 'Data Lead',\n",
       " 'Computational Biologist',\n",
       " 'Data Strategist',\n",
       " 'Principal Statistical Programmer',\n",
       " 'BI Engineer',\n",
       " 'Research Assistant',\n",
       " 'Backend Engineer',\n",
       " 'Full Stack Developer',\n",
       " 'Enterprise Account Executive',\n",
       " 'Business Analyst',\n",
       " 'Data Integration Analyst',\n",
       " 'Data Analytics Consultant',\n",
       " 'BI Developer',\n",
       " 'Research Associate',\n",
       " 'Machine Learning Researcher',\n",
       " 'Principal Researcher',\n",
       " 'AI Developer',\n",
       " 'QA Engineer',\n",
       " 'AI Researcher',\n",
       " 'Head of Data',\n",
       " 'Statistician',\n",
       " 'Risk Analyst',\n",
       " 'Data Governance Specialist',\n",
       " 'Data Operations Engineer',\n",
       " 'Tech Lead',\n",
       " 'Algorithm Developer',\n",
       " 'Cloud Engineer',\n",
       " 'Data Governance Lead',\n",
       " 'Data Management Lead',\n",
       " 'Data Analytics Specialist',\n",
       " 'Data Strategy Lead',\n",
       " 'Analytics Specialist',\n",
       " 'Analytics Lead',\n",
       " 'Data Analytics Developer',\n",
       " 'Data Modeler',\n",
       " 'Data Operations Manager',\n",
       " 'Quantitative Researcher',\n",
       " 'Product Analyst',\n",
       " 'Bioinformatics Scientist',\n",
       " 'BI Analyst',\n",
       " 'Quantitative Analyst',\n",
       " 'Robotics Engineer',\n",
       " 'Machine Learning Developer',\n",
       " 'Site Reliability Engineer',\n",
       " 'Analista de Datos',\n",
       " 'Big Data Analyst',\n",
       " 'Data Scientist Manager',\n",
       " 'Data Quality Lead',\n",
       " 'Pricing Analyst',\n",
       " 'Python Developer',\n",
       " 'Lead Data Engineer',\n",
       " 'Technical Writer',\n",
       " 'Lead Engineer',\n",
       " 'Machine Learning Lead',\n",
       " 'Data and Reporting Professional',\n",
       " 'Bioinformatician',\n",
       " 'AI Scientist',\n",
       " 'Computer Vision Engineer',\n",
       " 'Data Management Associate',\n",
       " 'AI Specialist',\n",
       " 'AI Engineering Manager',\n",
       " 'Member of Technical Staff',\n",
       " 'Machine Learning Specialist',\n",
       " 'Backend Developer',\n",
       " 'Data Operations Specialist',\n",
       " 'Data Analytics Lead',\n",
       " 'Machine Learning Engineer 5',\n",
       " 'Data Management Coordinator',\n",
       " 'Technology Integrator',\n",
       " 'Data Governance Manager',\n",
       " 'Business Intelligence Specialist',\n",
       " 'Prompt Engineer',\n",
       " 'Scala Spark Developer',\n",
       " 'AI Product Owner',\n",
       " 'Analytics Analyst',\n",
       " 'Controls Engineer',\n",
       " 'Data Integration Engineer',\n",
       " 'Machine Learning Tech Lead',\n",
       " 'Clinical Data Operator',\n",
       " 'Business Development Manager',\n",
       " 'AI Data Engineer',\n",
       " 'Cloud Database Administrator',\n",
       " 'Data Management Consultant',\n",
       " 'Master Data Management',\n",
       " 'Data Reporter',\n",
       " 'AI Lead',\n",
       " 'Business Insights Manager',\n",
       " 'Power BI Administrator',\n",
       " 'Data Operations Analyst',\n",
       " 'Machine Learning Architect',\n",
       " 'AI Research Scientist',\n",
       " 'AI Data Scientist',\n",
       " 'Software Architect',\n",
       " 'Cloud Database Engineer',\n",
       " 'Stage',\n",
       " 'Head of AI',\n",
       " 'Data Visualization Developer',\n",
       " 'Data Platform Engineer',\n",
       " 'Data Integration Developer',\n",
       " 'Business Intelligence Manager',\n",
       " 'Data Integration Specialist',\n",
       " 'Data Integrity Analyst',\n",
       " 'Platform Data Engineer',\n",
       " 'Bear Robotics',\n",
       " 'Principal Application Delivery Consultant',\n",
       " 'Data Visualization Specialist',\n",
       " 'Director of Machine Learning',\n",
       " 'Data Quality Specialist',\n",
       " 'Chatbot Developer',\n",
       " 'ETL Developer',\n",
       " 'Artificial Intelligence Engineer',\n",
       " 'Data Governance Architect',\n",
       " 'Power BI Consultant',\n",
       " 'Backend Software Engineer',\n",
       " 'Data Visualization Analyst',\n",
       " 'AI Product Manager',\n",
       " 'Data Operations Associate',\n",
       " 'Big Data Developer',\n",
       " 'ML Infrastructure Engineer',\n",
       " 'AI Machine Learning Engineer',\n",
       " 'Cloud Developer',\n",
       " 'Data Operations Lead',\n",
       " 'Fullstack Engineer',\n",
       " 'Machine Learning Quality Engineer',\n",
       " 'Security Engineer',\n",
       " 'Databricks Engineer',\n",
       " 'DataOps Engineer',\n",
       " 'Infrastructure Engineer',\n",
       " 'Solution Engineer',\n",
       " 'Big Data Engineer',\n",
       " 'Machine Learning Performance Engineer',\n",
       " 'Actuarial Analyst',\n",
       " 'Data Analytics Associate',\n",
       " 'Power BI Architect',\n",
       " 'Machine Learning Platform Engineer',\n",
       " 'AI Solution Architect',\n",
       " 'Data Scientist Lead',\n",
       " 'Machine Vision Engineer',\n",
       " 'Technical Specialist',\n",
       " 'Data Governance Engineer',\n",
       " 'Machine Learning Model Engineer',\n",
       " 'Marketing Analyst',\n",
       " 'Data Management Manager',\n",
       " 'Marketing Analytics Manager',\n",
       " 'Applied AI ML Lead',\n",
       " 'Data Strategy Manager',\n",
       " 'Machine Learning Manager',\n",
       " 'Data Product Analyst',\n",
       " 'Data Quality Manager',\n",
       " 'Elasticsearch Administrator',\n",
       " 'Machine Learning Infrastructure Engineer',\n",
       " 'People Data Analyst',\n",
       " 'Frontend Engineer',\n",
       " 'NLP Engineer',\n",
       " 'SAS Developer',\n",
       " 'Data Analytics Team Lead',\n",
       " 'Machine Learning Modeler',\n",
       " 'Data Integration Coordinator',\n",
       " 'AI Programmer',\n",
       " 'Admin & Data Analyst',\n",
       " 'Head of Business Intelligence',\n",
       " 'Head of Machine Learning',\n",
       " 'ETL Engineer',\n",
       " 'AI Research Engineer',\n",
       " 'Business Intelligence Consultant',\n",
       " 'Robotics Software Engineer',\n",
       " 'AI Software Engineer',\n",
       " 'Lead AI Engineer',\n",
       " 'AI Software Development Engineer',\n",
       " 'Master Data Specialist',\n",
       " 'Consultant Data Engineer',\n",
       " 'Manager Data Management',\n",
       " 'Director of Business Intelligence',\n",
       " 'Lead Data Scientist',\n",
       " 'Applied Research Scientist',\n",
       " 'CRM Data Analyst',\n",
       " 'BI Data Analyst',\n",
       " 'Applied Data Scientist',\n",
       " 'Data DevOps Engineer',\n",
       " 'Quantitative Research Analyst',\n",
       " 'Lead Machine Learning Engineer',\n",
       " 'Machine Learning Research Engineer',\n",
       " 'Data Analyst Lead',\n",
       " 'Data Pipeline Engineer',\n",
       " 'Lead Data Analyst',\n",
       " 'Business Data Analyst',\n",
       " 'Marketing Data Scientist',\n",
       " 'Deep Learning Engineer',\n",
       " 'Financial Data Analyst',\n",
       " 'Azure Data Engineer',\n",
       " 'Principal Data Scientist',\n",
       " 'Staff Data Analyst',\n",
       " 'Machine Learning Software Engineer',\n",
       " 'Applied Machine Learning Scientist',\n",
       " 'Principal Machine Learning Engineer',\n",
       " 'Principal Data Engineer',\n",
       " 'Staff Machine Learning Engineer',\n",
       " 'Staff Data Scientist',\n",
       " 'Business Intelligence Data Analyst',\n",
       " 'Finance Data Analyst',\n",
       " 'Software Data Engineer',\n",
       " 'Compliance Data Analyst',\n",
       " 'Cloud Data Engineer',\n",
       " 'Analytics Engineering Manager',\n",
       " 'AWS Data Architect',\n",
       " 'Product Data Analyst',\n",
       " 'Autonomous Vehicle Technician',\n",
       " 'Sales Data Analyst',\n",
       " 'Applied Machine Learning Engineer',\n",
       " 'BI Data Engineer',\n",
       " 'Deep Learning Researcher',\n",
       " 'Big Data Architect',\n",
       " 'Computer Vision Software Engineer',\n",
       " 'Marketing Data Engineer',\n",
       " 'Data Science Tech Lead',\n",
       " 'Marketing Data Analyst',\n",
       " 'Principal Data Architect',\n",
       " 'Data Analytics Engineer',\n",
       " 'Cloud Data Architect',\n",
       " 'Principal Data Analyst']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_title'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title\n",
       "Data Scientist                      11507\n",
       "Data Engineer                        9423\n",
       "Software Engineer                    7826\n",
       "Data Analyst                         7374\n",
       "Machine Learning Engineer            5815\n",
       "                                    ...  \n",
       "Applied Research Scientist              1\n",
       "People Data Analyst                     1\n",
       "AI Software Development Engineer        1\n",
       "Lead AI Engineer                        1\n",
       "Controls Engineer                       1\n",
       "Name: count, Length: 289, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title\n",
      "Data Scientist               11507\n",
      "Data Engineer                 9423\n",
      "Software Engineer             7826\n",
      "Data Analyst                  7374\n",
      "Machine Learning Engineer     5815\n",
      "Engineer                      4056\n",
      "Manager                       2506\n",
      "Research Scientist            2295\n",
      "Applied Scientist             1614\n",
      "Analyst                       1419\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_10 = df['job_title'].value_counts().head(10)\n",
    "\n",
    "print(top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Controls Engineer', 'Applied Research Scientist', 'AI Software Development Engineer', 'Lead AI Engineer', 'Analista de Datos', 'AI Machine Learning Engineer', 'Backend Software Engineer', 'Platform Data Engineer', 'Business Insights Manager', 'AI Data Engineer']\n"
     ]
    }
   ],
   "source": [
    "bottom_10 = df['job_title'].value_counts(ascending=True).head(10).index.tolist()\n",
    "print(bottom_10_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bottom 10 Least Recurring Values as a DataFrame:\n",
      "                                Value  Count\n",
      "0                   Controls Engineer      1\n",
      "1          Applied Research Scientist      1\n",
      "2    AI Software Development Engineer      1\n",
      "3                    Lead AI Engineer      1\n",
      "4                   Analista de Datos      1\n",
      "5        AI Machine Learning Engineer      1\n",
      "6           Backend Software Engineer      1\n",
      "7              Platform Data Engineer      1\n",
      "8           Business Insights Manager      1\n",
      "9                    AI Data Engineer      1\n",
      "10       Business Development Manager      1\n",
      "11               Cloud Data Architect      1\n",
      "12                  Analytics Analyst      1\n",
      "13        Machine Learning Engineer 5      1\n",
      "14             Data Scientist Manager      1\n",
      "15                   Big Data Analyst      1\n",
      "16                   CRM Data Analyst      1\n",
      "17      Quantitative Research Analyst      1\n",
      "18                People Data Analyst      1\n",
      "19           Marketing Data Scientist      1\n",
      "20           Principal Data Architect      1\n",
      "21    Staff Machine Learning Engineer      1\n",
      "22      Analytics Engineering Manager      1\n",
      "23                 AWS Data Architect      1\n",
      "24             Data Science Tech Lead      1\n",
      "25            Marketing Data Engineer      1\n",
      "26                 Sales Data Analyst      1\n",
      "27           Deep Learning Researcher      1\n",
      "28                   BI Data Engineer      1\n",
      "29                  Data Analyst Lead      2\n",
      "30                Power BI Consultant      2\n",
      "31          Data Governance Architect      2\n",
      "32      Autonomous Vehicle Technician      2\n",
      "33                      Data Reporter      2\n",
      "34                 Big Data Architect      2\n",
      "35                    Cloud Developer      2\n",
      "36              Scala Spark Developer      2\n",
      "37        Data Management Coordinator      2\n",
      "38                  Backend Developer      2\n",
      "39             AI Engineering Manager      2\n",
      "40             Marketing Data Analyst      2\n",
      "41         Machine Learning Tech Lead      2\n",
      "42               Data Operations Lead      2\n",
      "43                  Solution Engineer      2\n",
      "44             Data Pipeline Engineer      2\n",
      "45                Azure Data Engineer      2\n",
      "46  Director of Business Intelligence      2\n",
      "47            Manager Data Management      2\n",
      "48           Consultant Data Engineer      2\n",
      "49             Master Data Specialist      2\n"
     ]
    }
   ],
   "source": [
    "bottom_10_df = df['job_title'].value_counts(ascending=True).head(50).reset_index()\n",
    "bottom_10_df.columns = ['Value', 'Count']\n",
    "print(\"\\nBottom 10 Least Recurring Values as a DataFrame:\")\n",
    "print(bottom_10_df)\n",
    "\n",
    "# 28 unique jobtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_location  job_title                         \n",
      "AD                Data Scientist                        1\n",
      "AE                Machine Learning Engineer             2\n",
      "                  AI Engineer                           1\n",
      "                  Lead Data Scientist                   1\n",
      "AM                Data Analyst                          4\n",
      "                                                       ..\n",
      "ZA                Business Intelligence Analyst         2\n",
      "                  Data Strategist                       2\n",
      "                  Developer                             2\n",
      "                  Research Associate                    2\n",
      "                  Machine Learning Software Engineer    1\n",
      "Name: count, Length: 898, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "job_title_counts = df['job_title'].value_counts()\n",
    "\n",
    "# Filter job titles with more than 10 occurrences\n",
    "recurring_job_titles = job_title_counts[job_title_counts > 10].index\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = df[df['job_title'].isin(recurring_job_titles)]\n",
    "\n",
    "# Group by company location and count job titles\n",
    "grouped_by_location = filtered_df.groupby('company_location')['job_title'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_by_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US',\n",
       " 'NZ',\n",
       " 'CA',\n",
       " 'GB',\n",
       " 'AU',\n",
       " 'IN',\n",
       " 'DE',\n",
       " 'LT',\n",
       " 'SK',\n",
       " 'FR',\n",
       " 'AT',\n",
       " 'PH',\n",
       " 'AM',\n",
       " 'SG',\n",
       " 'LU',\n",
       " 'BR',\n",
       " 'NL',\n",
       " 'IT',\n",
       " 'CO',\n",
       " 'CL',\n",
       " 'PL',\n",
       " 'CY',\n",
       " 'ES',\n",
       " 'CD',\n",
       " 'CH',\n",
       " 'LV',\n",
       " 'IL',\n",
       " 'CZ',\n",
       " 'IE',\n",
       " 'JP',\n",
       " 'PE',\n",
       " 'KR',\n",
       " 'ZA',\n",
       " 'EG',\n",
       " 'PR',\n",
       " 'LB',\n",
       " 'GR',\n",
       " 'AR',\n",
       " 'FI',\n",
       " 'MX',\n",
       " 'DK',\n",
       " 'NG',\n",
       " 'BE',\n",
       " 'BG',\n",
       " 'EC',\n",
       " 'SV',\n",
       " 'CR',\n",
       " 'HU',\n",
       " 'PT',\n",
       " 'HR',\n",
       " 'KE',\n",
       " 'SE',\n",
       " 'UA',\n",
       " 'TR',\n",
       " 'PK',\n",
       " 'HN',\n",
       " 'MT',\n",
       " 'RO',\n",
       " 'VE',\n",
       " 'DZ',\n",
       " 'AS',\n",
       " 'RS',\n",
       " 'AE',\n",
       " 'SA',\n",
       " 'OM',\n",
       " 'BA',\n",
       " 'EE',\n",
       " 'VN',\n",
       " 'GI',\n",
       " 'SI',\n",
       " 'MU',\n",
       " 'RU',\n",
       " 'QA',\n",
       " 'GH',\n",
       " 'AD',\n",
       " 'NO',\n",
       " 'HK',\n",
       " 'CF',\n",
       " 'TH',\n",
       " 'IR',\n",
       " 'BS',\n",
       " 'ID',\n",
       " 'MY',\n",
       " 'IQ',\n",
       " 'CN',\n",
       " 'MD']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['company_location'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   job_title company_location  count\n",
      "0             Data Scientist               DE    120\n",
      "1               Data Analyst               FR    100\n",
      "2          Software Engineer               UK     80\n",
      "3  Machine Learning Engineer               IT     60\n"
     ]
    }
   ],
   "source": [
    "# Values to keep \n",
    "titles_to_keep = ['Data Scientist', 'Data Engineer', 'Software Engineer', 'Data Analyst', 'Machine Learning Engineer', 'Engineer', 'Manager', 'Research Scientist', 'Applied Scientist', 'Analyst']\n",
    "filtered_df = df[df['job_title'].isin(titles_to_keep)]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count\n",
      "count    4.000000\n",
      "mean    90.000000\n",
      "std     25.819889\n",
      "min     60.000000\n",
      "25%     75.000000\n",
      "50%     90.000000\n",
      "75%    105.000000\n",
      "max    120.000000\n"
     ]
    }
   ],
   "source": [
    "# Descriptive Statistics\n",
    "print(filtered_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                    job_title company_location  count\n",
       "0             Data Scientist               DE    120\n",
       "1               Data Analyst               FR    100\n",
       "2          Software Engineer               UK     80\n",
       "3  Machine Learning Engineer               IT     60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with Top 10 Job Titles\n",
    "data = {\n",
    "    'job_title': ['Data Scientist', 'Data Analyst', 'Software Engineer', 'Machine Learning Engineer', \n",
    "                  'Product Manager', 'UX Designer', 'Business Analyst', 'Backend Developer', \n",
    "                  'Frontend Developer', 'DevOps Engineer'],\n",
    "    'company_location': ['DE', 'FR', 'UK', 'IT', 'ES', 'NL', 'SE', 'FI', 'NO', 'PL'],\n",
    "    'count': [120, 100, 80, 60, 50, 45, 40, 35, 30, 25]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a Choropleth Map\n",
    "fig = px.choropleth(\n",
    "    df,\n",
    "    locations='company_location',      # Column with country codes\n",
    "    locationmode='ISO-3',              # Country codes are in ISO-3 format\n",
    "    color='count',                     # Data for coloring\n",
    "    hover_name='job_title',            # Information to display on hover\n",
    "    title='Geographical Distribution of Top 10 Job Titles in Europe',\n",
    "    color_continuous_scale='Viridis'   # Color scale\n",
    ")\n",
    "\n",
    "# Show the map\n",
    "fig.show()\n",
    "\n",
    "# Save the map as an HTML file\n",
    "fig.write_html(\"top_10_jobs_map.html\")\n",
    "print(\"Map saved as 'top_10_jobs_map.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title\n",
      "Analyst                      116492.117689\n",
      "Applied Scientist            181070.850062\n",
      "Data Analyst                 110138.770410\n",
      "Data Engineer                150868.320599\n",
      "Data Scientist               167052.683845\n",
      "Engineer                     175829.898422\n",
      "Machine Learning Engineer    201512.767326\n",
      "Manager                      169449.631285\n",
      "Research Scientist           196339.258824\n",
      "Software Engineer            189886.694991\n",
      "Name: salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# average salary by job_title\n",
    "\n",
    "avg_salary = filtered_df.groupby('job_title')['salary'].mean()\n",
    "print(avg_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as cvs\n",
    "\n",
    "filtered_df.to_csv('filtered_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/corneliastackhouse/Documents/Greenbootcamps/Project_Data_Professions_career_shift/data/salaries.csv') \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_jobs = df['job_title'].value_counts().head(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['job_title'].isin(top_10_jobs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = filtered_df.groupby('company_location').size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbformat --upgrade -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   job_title company_location  count\n",
      "0             Data Scientist               DE    120\n",
      "1               Data Analyst               FR    100\n",
      "2          Software Engineer               UK     80\n",
      "3  Machine Learning Engineer               IT     60\n",
      "4            Product Manager               ES     50\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   job_title         10 non-null     object\n",
      " 1   company_location  10 non-null     object\n",
      " 2   count             10 non-null     int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 372.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'builtins.str' received for the 'locationmode' property of choropleth\n        Received value: 'ISO-2'\n\n    The 'locationmode' property is an enumeration that may be specified as:\n      - One of the following enumeration values:\n            ['ISO-3', 'USA-states', 'country names', 'geojson-id']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Create a Choropleth Map\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoropleth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompany_location\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Column with country codes\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocationmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mISO-2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Country codes are in ISO-3 format\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# Data for coloring\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhover_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjob_title\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Information to display on hover\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGeographical Distribution of Top 10 Job Titles in Europe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_continuous_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mViridis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Color scale\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Show the map\u001b[39;00m\n\u001b[1;32m     26\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/plotly/express/_chart_types.py:1091\u001b[0m, in \u001b[0;36mchoropleth\u001b[0;34m(data_frame, lat, lon, locations, locationmode, geojson, featureidkey, color, facet_row, facet_col, facet_col_wrap, facet_row_spacing, facet_col_spacing, hover_name, hover_data, custom_data, animation_frame, animation_group, category_orders, labels, color_discrete_sequence, color_discrete_map, color_continuous_scale, range_color, color_continuous_midpoint, projection, scope, center, fitbounds, basemap_visible, title, template, width, height)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchoropleth\u001b[39m(\n\u001b[1;32m   1052\u001b[0m     data_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1053\u001b[0m     lat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1086\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure:\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;124;03m    In a choropleth map, each row of `data_frame` is represented by a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;124;03m    colored region mark on a map.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1091\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_figure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChoropleth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrace_patch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlocationmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocationmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/plotly/express/_core.py:2300\u001b[0m, in \u001b[0;36mmake_figure\u001b[0;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[1;32m   2295\u001b[0m         group[var] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100.0\u001b[39m \u001b[38;5;241m*\u001b[39m group[var] \u001b[38;5;241m/\u001b[39m group_sum\n\u001b[1;32m   2297\u001b[0m patch, fit_results \u001b[38;5;241m=\u001b[39m make_trace_kwargs(\n\u001b[1;32m   2298\u001b[0m     args, trace_spec, group, mapping_labels\u001b[38;5;241m.\u001b[39mcopy(), sizeref\n\u001b[1;32m   2299\u001b[0m )\n\u001b[0;32m-> 2300\u001b[0m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2302\u001b[0m     trendline_rows\u001b[38;5;241m.\u001b[39mappend(mapping_labels\u001b[38;5;241m.\u001b[39mcopy())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/plotly/basedatatypes.py:5133\u001b[0m, in \u001b[0;36mBasePlotlyType.update\u001b[0;34m(self, dict1, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m   5131\u001b[0m         BaseFigure\u001b[38;5;241m.\u001b[39m_perform_update(\u001b[38;5;28mself\u001b[39m, kwargs, overwrite\u001b[38;5;241m=\u001b[39moverwrite)\n\u001b[1;32m   5132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5133\u001b[0m     \u001b[43mBaseFigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5134\u001b[0m     BaseFigure\u001b[38;5;241m.\u001b[39m_perform_update(\u001b[38;5;28mself\u001b[39m, kwargs, overwrite\u001b[38;5;241m=\u001b[39moverwrite)\n\u001b[1;32m   5136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/plotly/basedatatypes.py:3934\u001b[0m, in \u001b[0;36mBaseFigure._perform_update\u001b[0;34m(plotly_obj, update_obj, overwrite)\u001b[0m\n\u001b[1;32m   3931\u001b[0m                 plotly_obj[key] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m   3932\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3933\u001b[0m             \u001b[38;5;66;03m# Assign non-compound value\u001b[39;00m\n\u001b[0;32m-> 3934\u001b[0m             \u001b[43mplotly_obj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m   3936\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(plotly_obj, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   3938\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(update_obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3939\u001b[0m         \u001b[38;5;66;03m# Nothing to do\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/plotly/basedatatypes.py:4868\u001b[0m, in \u001b[0;36mBasePlotlyType.__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   4864\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_array_prop(prop, value)\n\u001b[1;32m   4866\u001b[0m     \u001b[38;5;66;03m# ### Handle simple property ###\u001b[39;00m\n\u001b[1;32m   4867\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4868\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4869\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4870\u001b[0m     \u001b[38;5;66;03m# Make sure properties dict is initialized\u001b[39;00m\n\u001b[1;32m   4871\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_props()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/plotly/basedatatypes.py:5212\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5210\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   5211\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5212\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   5214\u001b[0m \u001b[38;5;66;03m# val is None\u001b[39;00m\n\u001b[1;32m   5215\u001b[0m \u001b[38;5;66;03m# -----------\u001b[39;00m\n\u001b[1;32m   5216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5217\u001b[0m     \u001b[38;5;66;03m# Check if we should send null update\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/plotly/basedatatypes.py:5207\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5204\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_validator(prop)\n\u001b[1;32m   5206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5207\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_coerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   5209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_invalid:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:619\u001b[0m, in \u001b[0;36mEnumeratedValidator.validate_coerce\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    617\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperform_replacemenet(v)\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_values(v):\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_invalid_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:296\u001b[0m, in \u001b[0;36mBaseValidator.raise_invalid_val\u001b[0;34m(self, v, inds)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[1;32m    294\u001b[0m                 name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 296\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    297\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    Invalid value of type {typ} received for the '{name}' property of {pname}\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m        Received value: {v}\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m{valid_clr_desc}\"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    302\u001b[0m                 name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    303\u001b[0m                 pname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_name,\n\u001b[1;32m    304\u001b[0m                 typ\u001b[38;5;241m=\u001b[39mtype_str(v),\n\u001b[1;32m    305\u001b[0m                 v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(v),\n\u001b[1;32m    306\u001b[0m                 valid_clr_desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription(),\n\u001b[1;32m    307\u001b[0m             )\n\u001b[1;32m    308\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: \n    Invalid value of type 'builtins.str' received for the 'locationmode' property of choropleth\n        Received value: 'ISO-2'\n\n    The 'locationmode' property is an enumeration that may be specified as:\n      - One of the following enumeration values:\n            ['ISO-3', 'USA-states', 'country names', 'geojson-id']"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with Top 10 Job Titles\n",
    "data = {\n",
    "    'job_title': ['Data Scientist', 'Data Analyst', 'Software Engineer', 'Machine Learning Engineer', \n",
    "                  'Product Manager', 'UX Designer', 'Business Analyst', 'Backend Developer', \n",
    "                  'Frontend Developer', 'DevOps Engineer'],\n",
    "    'company_location': ['DE', 'FR', 'UK', 'IT', 'ES', 'NL', 'SE', 'FI', 'NO', 'PL'],\n",
    "    'count': [120, 100, 80, 60, 50, 45, 40, 35, 30, 25]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a Choropleth Map\n",
    "fig = px.choropleth(\n",
    "    df,\n",
    "    locations='company_location',      # Column with country codes\n",
    "    locationmode='ISO-3',              # Country codes are in ISO-3 format\n",
    "    color='count',                     # Data for coloring\n",
    "    hover_name='job_title',            # Information to display on hover\n",
    "    title='Geographical Distribution of Top 10 Job Titles in Europe',\n",
    "    color_continuous_scale='Viridis'   # Color scale\n",
    ")\n",
    "\n",
    "# Show the map\n",
    "fig.show()\n",
    "\n",
    "# Save the map as an HTML file\n",
    "fig.write_html(\"top_10_jobs_map.html\")\n",
    "print(\"Map saved as 'top_10_jobs_map.html'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
